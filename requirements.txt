# requirements.txt - Python Dependencies

# Web Scraping
selenium==4.15.2
beautifulsoup4==4.12.2
requests==2.31.0
lxml==4.9.3

# OCR
pytesseract==0.3.10
opencv-python==4.8.1.78
Pillow==10.1.0

# Database
SQLAlchemy==2.0.23
alembic==1.12.1

# API
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-multipart==0.0.6

# Data Export
pandas==2.1.3

# Utilities
python-dotenv==1.0.0
pydantic==2.5.0

# Testing (optional)
pytest==7.4.3
pytest-asyncio==0.21.1

# ---

# .env.example - Environment Variables Template

# Database
DATABASE_URL=sqlite:///data/database/products.db

# Selenium
CHROME_DRIVER_PATH=/usr/local/bin/chromedriver
HEADLESS=true

# Tesseract
TESSERACT_CMD=/usr/bin/tesseract

# API
API_HOST=0.0.0.0
API_PORT=8000
API_WORKERS=4

# Scraping
USER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36
REQUEST_TIMEOUT=30
RATE_LIMIT_DELAY=2

# Export
EXPORT_DIR=./data/exports

# ---

# .gitignore

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg

# Virtual Environment
venv/
ENV/
env/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# Data
data/database/*.db
data/exports/*.json
data/exports/*.csv
data/flyers/*.jpg
data/flyers/*.png

# Logs
*.log

# Environment
.env

# OS
.DS_Store
Thumbs.db

# ---

# README.md

# ğŸ‡ªğŸ‡¬ Egyptian Grocery Scraper

Complete Python scraping application for Egyptian grocery stores (Carrefour, Metro, Kazyon) with OCR support, REST API, and automated exports for the **OfferCatalog** React Native mobile app.

## ğŸ› ï¸ Tech Stack

- **Scrapers**: Selenium + BeautifulSoup (Carrefour), Requests + BeautifulSoup (Metro)
- **OCR**: Pytesseract + OpenCV (Kazyon flyers)
- **Database**: SQLite + SQLAlchemy
- **API**: FastAPI + Uvicorn
- **Export**: JSON/CSV for mobile app
- **Automation**: GitHub Actions (daily scraping at 6 AM)

## ğŸš€ Quick Start

### Installation

```bash
# Clone repository
git clone https://github.com/aliattia02/data_scrapper.git
cd data_scrapper

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install system dependencies
# Ubuntu/Debian:
sudo apt-get install tesseract-ocr tesseract-ocr-ara chromium-chromedriver

# macOS:
brew install tesseract tesseract-lang chromedriver

# Initialize database
python -m src.main db init
```

### Usage

```bash
# Run scrapers
python -m src.main scrape --all                    # All stores
python -m src.main scrape --store carrefour        # Specific store

# Process flyers with OCR
python -m src.main ocr --input ./data/flyers/kazyon.jpg
python -m src.main ocr --batch ./data/flyers/      # Batch process

# Export data
python -m src.main export --format json            # For mobile app
python -m src.main export --format csv             # For analysis

# Start API server
python -m src.main serve --port 8000               # Access at localhost:8000/docs
```

## ğŸ“± API Endpoints

- `GET /products` - List products with filters
- `GET /products/{id}` - Get single product
- `GET /products/search?q={query}` - Search products
- `GET /stores` - List available stores
- `GET /categories` - List categories (AR/EN)
- `GET /deals` - Get best deals
- `GET /stats` - Overall statistics

## ğŸ”„ Automated Scraping

GitHub Actions runs daily at 6 AM Egypt time:
- Scrapes all stores
- Processes Kazyon flyers
- Exports fresh JSON/CSV
- Uploads artifacts

## ğŸ“‚ Project Structure

```
data_scrapper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py              # CLI entry point
â”‚   â”œâ”€â”€ scrapers/            # Store scrapers
â”‚   â”œâ”€â”€ ocr/                 # OCR processing
â”‚   â”œâ”€â”€ database/            # SQLAlchemy models
â”‚   â”œâ”€â”€ api/                 # FastAPI app
â”‚   â”œâ”€â”€ exporters/           # JSON/CSV exporters
â”‚   â””â”€â”€ utils/               # Egyptian categories
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ flyers/              # Input images
â”‚   â”œâ”€â”€ exports/             # JSON/CSV outputs
â”‚   â””â”€â”€ database/            # SQLite database
â””â”€â”€ .github/workflows/       # Automated scraping

```

## ğŸ”— Connected Repository

This scraper feeds data to: **[aliattia02/OfferCatalog](https://github.com/aliattia02/OfferCatalog)** (React Native mobile app)

## ğŸ“„ License

MIT