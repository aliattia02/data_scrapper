name: Daily Scraping

on:
  schedule:
    # Run daily at 6 AM Egypt time (4 AM UTC)
    - cron: '0 4 * * *'
  workflow_dispatch:  # Allow manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y tesseract-ocr tesseract-ocr-ara chromium-chromedriver
      
      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Initialize database
        run: |
          python -m src.main db init
      
      - name: Run scrapers
        run: |
          python -m src.main scrape --store all
      
      - name: Export data
        run: |
          python -m src.main export --format json
          python -m src.main export --format csv
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v3
        with:
          name: scraped-data
          path: data/exports/
          retention-days: 30
      
      - name: Commit and push data
        run: |
          git config --global user.name 'GitHub Actions'
          git config --global user.email 'actions@github.com'
          git add data/exports/
          git commit -m "Update scraped data - $(date +'%Y-%m-%d %H:%M:%S')" || echo "No changes to commit"
          git push || echo "Nothing to push"
